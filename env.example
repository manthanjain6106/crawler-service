# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# Crawler Configuration
MAX_CONCURRENT_REQUESTS=30
DEFAULT_TIMEOUT=30
MAX_DEPTH=10

# Advanced Concurrency Settings
CONCURRENCY_BURST_LIMIT=50
CONCURRENCY_GRADUAL_INCREASE=true

# Rate Limiting
RATE_LIMIT_PER_MINUTE=10

# Per-Domain Rate Limiting
ENABLE_PER_DOMAIN_RATE_LIMITING=true
DEFAULT_DOMAIN_RATE_LIMIT=10
DOMAIN_RATE_LIMIT_WINDOW=60
# Domain-specific limits (format: domain:limit,domain:limit)
# Example: example.com:5,api.example.com:20,slow-site.com:2
DOMAIN_SPECIFIC_LIMITS=

# Redis Configuration (for production)
REDIS_URL=redis://localhost:6379
USE_REDIS=false

# Background Job Processing
# Enable background job processing with Redis
ENABLE_BACKGROUND_JOBS=true
# Maximum number of worker processes
MAX_WORKERS=2
# Job timeout in seconds
JOB_TIMEOUT=3600

# Logging
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Use DEBUG for development/testing, INFO for production
LOG_LEVEL=INFO
# Environment: development, testing, production
ENVIRONMENT=development

# Security
ALLOWED_ORIGINS=*

# Error Handling & Retry Settings
MAX_RETRIES=3
RETRY_DELAY_BASE=1.0
RETRY_DELAY_MAX=10.0
RETRY_BACKOFF_MULTIPLIER=2.0
RETRY_ON_TIMEOUT=true
RETRY_ON_CONNECTION_ERROR=true

# Storage Configuration
# Storage type: json, mongodb, elasticsearch
STORAGE_TYPE=json
STORAGE_DATA_DIR=data

# MongoDB Configuration (for STORAGE_TYPE=mongodb)
MONGODB_URL=mongodb://localhost:27017
MONGODB_DATABASE=crawler_service

# Elasticsearch Configuration (for STORAGE_TYPE=elasticsearch)
ELASTICSEARCH_HOSTS=localhost:9200
ELASTICSEARCH_CLOUD_ID=
ELASTICSEARCH_API_KEY=
ELASTICSEARCH_USERNAME=
ELASTICSEARCH_PASSWORD=
ELASTICSEARCH_INDEX_PREFIX=crawler